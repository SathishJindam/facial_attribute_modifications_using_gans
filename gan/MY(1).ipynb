{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MY(1).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Lvq8GIIk4Rcp","colab_type":"code","outputId":"d2ddf244-c71e-41d1-a8bd-ec29f5c02547","executionInfo":{"status":"ok","timestamp":1584186842927,"user_tz":-330,"elapsed":19481,"user":{"displayName":"sathish jindam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxqAGaa0hvMFGMa4Ar_3wItgXU-JokaQn9-QGgKw=s64","userId":"12274474612273129219"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kTCZ--vSjeaw","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"fFpg0HB34RY2","colab_type":"code","outputId":"d8927f90-d640-4dc4-b73e-b455384f902d","executionInfo":{"status":"ok","timestamp":1584186852857,"user_tz":-330,"elapsed":2322,"user":{"displayName":"sathish jindam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxqAGaa0hvMFGMa4Ar_3wItgXU-JokaQn9-QGgKw=s64","userId":"12274474612273129219"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd .."],"execution_count":2,"outputs":[{"output_type":"stream","text":["/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G7gqnkXR4RV_","colab_type":"code","outputId":"b96a4d0f-38da-4adb-f1fb-87e8636f246c","executionInfo":{"status":"ok","timestamp":1584186855434,"user_tz":-330,"elapsed":1732,"user":{"displayName":"sathish jindam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxqAGaa0hvMFGMa4Ar_3wItgXU-JokaQn9-QGgKw=s64","userId":"12274474612273129219"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd 'gdrive/My Drive/gan'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/gan\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9yCRbj2SaeGy","colab_type":"text"},"source":["# **Finding Path Names**"]},{"cell_type":"code","metadata":{"id":"lVSeCf9Y8mwL","colab_type":"code","colab":{}},"source":["# import os\n","# root =os.walk('data/img_align_celeba_/')\n","# total=list(root)\n","# paths=[]\n","# for hint in total[1:]:\n","#     path,_,files = hint\n","#     temp=[path+'/'+x for x in files]\n","#     paths.append(temp)\n","# import pandas as pd\n","# path_flatten=[actual  for x in paths for actual in x]\n","# # path_flatten\n","# file_names=pd.DataFrame(path_flatten,columns=['name'])\n","# file_names['id']=pd.Series([x[3] for x in file_names['name'].str.split('/')])\n","\n","# file_names=file_names[file_names['id'].str.len()>4]\n","\n","# file_names['name'] = file_names['name'].apply(lambda x : x[5:])\n","# file_names['id']=file_names['id'].apply(lambda x : int(x.split('.')[0]))\n","# file_names = file_names.set_index('id')\n","# file_names.sort_index(inplace=True)\n","# file_names.to_csv('file_names',index=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NhDcML83awoH","colab_type":"text"},"source":["# Reading filenames"]},{"cell_type":"code","metadata":{"id":"zImPCR2HhTjK","colab_type":"code","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cKJcouB6Wvbh","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"GLS05RgDZ4Py","colab_type":"code","colab":{}},"source":["file_names=pd.read_csv('file_names')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mAPBnaEYa1wX","colab_type":"text"},"source":["# Importing Tensorflow and other necesarry Modules"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:35.750877Z","start_time":"2019-03-23T12:11:23.942431Z"},"id":"DDGFK5yd36JZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203},"outputId":"650c03bd-62d3-45a1-c0b1-01c80eda865b","executionInfo":{"status":"ok","timestamp":1584186883304,"user_tz":-330,"elapsed":4904,"user":{"displayName":"sathish jindam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxqAGaa0hvMFGMa4Ar_3wItgXU-JokaQn9-QGgKw=s64","userId":"12274474612273129219"}}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import re\n","import numpy as np\n","import scipy.misc\n","\n","import tensorflow as tf\n","import tensorflow.contrib.slim as slim\n","\n","import my_time\n","\n","from Tflib import session\n","\n","import data\n","import models\n","\n","import datetime\n","from functools import partial\n","import traceback\n","import os\n"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-6m4W23z36Jf","colab_type":"text"},"source":["# Imlib"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:35.763998Z","start_time":"2019-03-23T12:11:35.756933Z"},"id":"RiN0Nkxf36Jg","colab_type":"code","colab":{}},"source":["\n","\n","\n","def immerge(images, row, col):\n","    \"\"\"Merge images into an image with (row * h) * (col * w).\n","\n","    `images` is in shape of N * H * W(* C=1 or 3)\n","    \"\"\"\n","    h, w = images.shape[1], images.shape[2]\n","    if images.ndim == 4:\n","        img = np.zeros((h * row, w * col, images.shape[3]))\n","    elif images.ndim == 3:\n","        img = np.zeros((h * row, w * col))\n","    for idx, image in enumerate(images):\n","        i = idx % col\n","        j = idx // col\n","        img[j * h:j * h + h, i * w:i * w + w, ...] = image\n","\n","    return img\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:37.775263Z","start_time":"2019-03-23T12:11:37.772233Z"},"id":"390B9Zu536Jk","colab_type":"code","colab":{}},"source":["\n","def to_range(images, min_value=0.0, max_value=1.0, dtype=None):\n","    \"\"\"Transform images from [-1.0, 1.0] to [min_value, max_value] of dtype.\"\"\"\n","    assert np.min(images) >= -1.0 - 1e-5 and np.max(images) <= 1.0 + 1e-5 \\\n","        and (images.dtype == np.float32 or images.dtype == np.float64), \\\n","        ('The input images should be float64(32) '\n","         'and in the range of [-1.0, 1.0]!')\n","    if dtype is None:\n","        dtype = images.dtype\n","    return ((images + 1.) / 2. * (max_value - min_value) +\n","            min_value).astype(dtype)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:37.917577Z","start_time":"2019-03-23T12:11:37.914864Z"},"id":"JlZAhO8M36Jn","colab_type":"code","colab":{}},"source":["def imwrite(image, path):\n","    \"\"\"Save an [-1.0, 1.0] image.\"\"\"\n","    if image.ndim == 3 and image.shape[2] == 1:  # for gray image\n","        image = np.array(image, copy=True)\n","        image.shape = image.shape[0:2]\n","    return scipy.misc.imsave(path, to_range(image, 0, 255, np.uint8))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6-EoV4IC36Jp","colab_type":"text"},"source":["# Pylib"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:38.238496Z","start_time":"2019-03-23T12:11:38.233580Z"},"id":"kayc5zgu36Jq","colab_type":"code","colab":{}},"source":["\n","def mkdir(paths):\n","    \n","    if not isinstance(paths, (list, tuple)):\n","        paths = [paths]\n","    for path in paths:\n","        if not os.path.isdir(path):\n","            os.makedirs(path)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"60hYlqsN36Js","colab_type":"text"},"source":["# Tflib"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:38.582716Z","start_time":"2019-03-23T12:11:38.577634Z"},"id":"GS-VVbkr36Jt","colab_type":"code","colab":{}},"source":["def load_checkpoint(ckpt_dir_or_file, session, var_list=None):\n","\n","    if os.path.isdir(ckpt_dir_or_file):\n","        ckpt_dir_or_file = tf.train.latest_checkpoint(ckpt_dir_or_file)\n","\n","    restorer = tf.train.Saver(var_list)\n","    restorer.restore(session, ckpt_dir_or_file)\n","    print(' [*] Loading checkpoint succeeds! Copy variables from % s!' % ckpt_dir_or_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:39.053017Z","start_time":"2019-03-23T12:11:39.043778Z"},"id":"wzQQ3xft36Jv","colab_type":"code","colab":{}},"source":["\n","def summary(tensor_collection,\n","            summary_type=['mean', 'stddev', 'max', 'min', 'sparsity', 'histogram'],\n","            scope=None):\n","    \"\"\"Summary.\n","\n","    usage:\n","        1. summary(tensor)\n","        2. summary([tensor_a, tensor_b])\n","        3. summary({tensor_a: 'a', tensor_b: 'b})\n","    \"\"\"\n","    def _summary(tensor, name, summary_type):\n","        \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n","        if name is None:\n","            # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n","            # session. This helps the clarity of presentation on tensorboard.\n","            name = re.sub('%s_[0-9]*/' % 'tower', '', tensor.name)\n","            name = re.sub(':', '-', name)\n","\n","        summaries = []\n","        if len(tensor.shape) == 0:\n","            summaries.append(tf.summary.scalar(name, tensor))\n","        else:\n","            if 'mean' in summary_type:\n","                mean = tf.reduce_mean(tensor)\n","                summaries.append(tf.summary.scalar(name + '/mean', mean))\n","            if 'stddev' in summary_type:\n","                mean = tf.reduce_mean(tensor)\n","                stddev = tf.sqrt(tf.reduce_mean(tf.square(tensor - mean)))\n","                summaries.append(tf.summary.scalar(name + '/stddev', stddev))\n","            if 'max' in summary_type:\n","                summaries.append(tf.summary.scalar(name + '/max', tf.reduce_max(tensor)))\n","            if 'min' in summary_type:\n","                summaries.append(tf.summary.scalar(name + '/min', tf.reduce_min(tensor)))\n","            if 'sparsity' in summary_type:\n","                summaries.append(tf.summary.scalar(name + '/sparsity', tf.nn.zero_fraction(tensor)))\n","            if 'histogram' in summary_type:\n","                summaries.append(tf.summary.histogram(name, tensor))\n","        return tf.summary.merge(summaries)\n","\n","    if not isinstance(tensor_collection, (list, tuple, dict)):\n","        tensor_collection = [tensor_collection]\n","\n","    with tf.name_scope(scope, 'summary'):\n","        summaries = []\n","        if isinstance(tensor_collection, (list, tuple)):\n","            for tensor in tensor_collection:\n","                summaries.append(_summary(tensor, None, summary_type))\n","        else:\n","            for tensor, name in tensor_collection.items():\n","                summaries.append(_summary(tensor, name, summary_type))\n","        return tf.summary.merge(summaries)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:39.657910Z","start_time":"2019-03-23T12:11:39.642162Z"},"id":"Bu6twTxH36Jz","colab_type":"code","colab":{}},"source":["\n","def counter(start=0, scope=None):\n","    with tf.variable_scope(scope, 'counter'):\n","        counter = tf.get_variable(name='counter',\n","                                  initializer=tf.constant_initializer(start),\n","                                  shape=(),\n","                                  dtype=tf.int64)\n","        update_cnt = tf.assign(counter, tf.add(counter, 1))\n","        return counter, update_cnt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:40.343492Z","start_time":"2019-03-23T12:11:40.337115Z"},"id":"BVzuJqCH36J5","colab_type":"code","colab":{}},"source":["\n","def tensors_filter(tensors, filters, combine_type='or'):\n","    assert isinstance(tensors, (list, tuple)), '`tensors` shoule be a list or tuple!'\n","    assert isinstance(filters, (str, list, tuple)), '`filters` should be a string or a list(tuple) of strings!'\n","    assert combine_type == 'or' or combine_type == 'and', \"`combine_type` should be 'or' or 'and'!\"\n","\n","    if isinstance(filters, str):\n","        filters = [filters]\n","\n","    f_tens = []\n","    for ten in tensors:\n","        if combine_type == 'or':\n","            for filt in filters:\n","                if filt in ten.name:\n","                    f_tens.append(ten)\n","                    break\n","        elif combine_type == 'and':\n","            all_pass = True\n","            for filt in filters:\n","                if filt not in ten.name:\n","                    all_pass = False\n","                    break\n","            if all_pass:\n","                f_tens.append(ten)\n","    return f_tens"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:40.997014Z","start_time":"2019-03-23T12:11:40.992532Z"},"id":"_9NrHJNT36J8","colab_type":"code","colab":{}},"source":["def trainable_variables(filters=None, combine_type='or'):\n","    t_var = tf.trainable_variables()\n","    if filters is None:\n","        return t_var\n","    else:\n","        return tensors_filter(t_var, filters, combine_type)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:42.473349Z","start_time":"2019-03-23T12:11:42.468315Z"},"id":"oyb7p58836KA","colab_type":"code","colab":{}},"source":["\n","# ==============================================================================\n","# =                                    param                                   =\n","# ==============================================================================\n","def init_settings():\n","    \n","    global experiment_name,atts,n_att,img_size,shortcut_layers,inject_layers,enc_dim,dec_dim,dis_dim,dis_fc_dim,enc_layers,dec_layers,dis_layers,\\\n","     mode,epoch,batch_size,lr_base,n_d,b_distribution,thres_int,test_int,n_sample,use_cropped_img,experiment_name\n","    atts =  ['Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Bushy_Eyebrows', 'Eyeglasses', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'No_Beard', 'Pale_Skin', 'Young']\n","    n_att = len(atts)\n","    img_size = 128\n","    shortcut_layers = 1\n","    inject_layers = 1\n","    enc_dim = 64\n","    dec_dim = 64\n","    dis_dim = 64\n","    dis_fc_dim = 1024\n","    enc_layers = 5\n","    dec_layers = 5\n","    dis_layers = 5\n","    # training\n","    mode = 'wgan'\n","    epoch = 200\n","    batch_size = 32\n","    lr_base = 0.0002\n","    n_d = 5\n","    b_distribution = 'none'\n","    thres_int = 0.5\n","    test_int = 1\n","    n_sample = 64\n","    # others\n","    use_cropped_img = False\n","    experiment_name = 'training'\n","    \n","    \n","def intiliaze_models():\n","    # models\n","    Genc = partial(models.Genc, dim=enc_dim, n_layers=enc_layers)\n","    Gdec = partial(models.Gdec, dim=dec_dim, n_layers=dec_layers, shortcut_layers=shortcut_layers, inject_layers=inject_layers)\n","    D = partial(models.D, n_att=n_att, dim=dis_dim, fc_dim=dis_fc_dim, n_layers=dis_layers)\n","\n","    return Genc,Gdec,D\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:43.404256Z","start_time":"2019-03-23T12:11:43.401841Z"},"id":"rFDww_0536KB","colab_type":"code","colab":{}},"source":["\n","def load_ckpt():\n","    ckpt_dir = 'output/%s/'%experiment_name\n","    \n","\n","    try:\n","        load_checkpoint(ckpt_dir, sess)\n","    except:\n","        sess.run(tf.global_variables_initializer())\n","    return ckpt_dir"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:11:44.668961Z","start_time":"2019-03-23T12:11:44.665480Z"},"id":"zy4nh9TO36KE","colab_type":"code","colab":{}},"source":["\n","# data\n","def load_train_data():\n","    \n","\n","    tr_data = data.Celeba(file_names.name.tolist(),'data/', atts, img_size, batch_size, part='train', sess=sess, crop=not use_cropped_img)\n","    val_data = data.Celeba(file_names.name.tolist(),'data/', atts, img_size, n_sample, part='val', shuffle=False, sess=sess, crop=not use_cropped_img)\n","    return tr_data,val_data\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"08BQiIyxSh6U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"bac4ba7a-b262-463c-e2be-41c96e94326c","executionInfo":{"status":"ok","timestamp":1584186932837,"user_tz":-330,"elapsed":2520,"user":{"displayName":"sathish jindam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxqAGaa0hvMFGMa4Ar_3wItgXU-JokaQn9-QGgKw=s64","userId":"12274474612273129219"}}},"source":["\n","sess = session()\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /gdrive/My Drive/gan/Tflib.py:7: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /gdrive/My Drive/gan/Tflib.py:10: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uiZXobnAsYRb","colab_type":"code","outputId":"a3b008ef-3dd2-4481-fd5b-dab18d481c47","executionInfo":{"status":"ok","timestamp":1584186934601,"user_tz":-330,"elapsed":679,"user":{"displayName":"sathish jindam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxqAGaa0hvMFGMa4Ar_3wItgXU-JokaQn9-QGgKw=s64","userId":"12274474612273129219"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["sess.list_devices()"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 7568465941638759721),\n"," _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 13607084344740819421),\n"," _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 4243338834018270873),\n"," _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 7470045594, 110126357559606888)]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T07:02:33.577217Z","start_time":"2019-03-22T14:27:26.469763Z"},"scrolled":true,"id":"_Hp4ekbp36KH","colab_type":"code","outputId":"0138e329-e2ea-4544-c662-86ed25e796d9","executionInfo":{"status":"error","timestamp":1584186963519,"user_tz":-330,"elapsed":1125,"user":{"displayName":"sathish jindam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxqAGaa0hvMFGMa4Ar_3wItgXU-JokaQn9-QGgKw=s64","userId":"12274474612273129219"}},"colab":{"base_uri":"https://localhost:8080/","height":358}},"source":["\n","init_settings()\n","\n","Genc,Gdec,D = intiliaze_models()\n","\n","\n","tr_data,val_data = load_train_data()\n","\n","\n","\n","lr = tf.placeholder(dtype=tf.float32, shape=[])\n","\n","xa = tr_data.batch_op[0]\n","a = tr_data.batch_op[1]\n","b = tf.random_shuffle(a)\n","_a = (tf.to_float(a) * 2 - 1) * thres_int\n","if b_distribution == 'none':\n","    _b = (tf.to_float(b) * 2 - 1) * thres_int\n","elif b_distribution == 'uniform':\n","    _b = (tf.to_float(b) * 2 - 1) * tf.random_uniform(tf.shape(b)) * (2 * thres_int)\n","elif b_distribution == 'truncated_normal':\n","    _b = (tf.to_float(b) * 2 - 1) * (tf.truncated_normal(tf.shape(b)) + 2) / 4.0 * (2 * thres_int)\n","\n","xa_sample = tf.placeholder(tf.float32, shape=[None, img_size, img_size, 3])\n","_b_sample = tf.placeholder(tf.float32, shape=[None, n_att])\n","\n","# generate\n","z = Genc(xa)\n","xb_ = Gdec(z, _b)\n","with tf.control_dependencies([xb_]):\n","    xa_ = Gdec(z, _a)\n","\n","# discriminate\n","xa_logit_gan, xa_logit_att = D(xa)\n","xb__logit_gan, xb__logit_att = D(xb_)\n","\n","# discriminator losses\n","if mode == 'wgan':  # wgan-gp\n","    wd = tf.reduce_mean(xa_logit_gan) - tf.reduce_mean(xb__logit_gan)\n","    d_loss_gan = -wd\n","    gp = models.gradient_penalty(D, xa, xb_)\n","elif mode == 'lsgan':  # lsgan-gp\n","    xa_gan_loss = tf.losses.mean_squared_error(tf.ones_like(xa_logit_gan), xa_logit_gan)\n","    xb__gan_loss = tf.losses.mean_squared_error(tf.zeros_like(xb__logit_gan), xb__logit_gan)\n","    d_loss_gan = xa_gan_loss + xb__gan_loss\n","    gp = models.gradient_penalty(D, xa)\n","elif mode == 'dcgan':  # dcgan-gp\n","    xa_gan_loss = tf.losses.sigmoid_cross_entropy(tf.ones_like(xa_logit_gan), xa_logit_gan)\n","    xb__gan_loss = tf.losses.sigmoid_cross_entropy(tf.zeros_like(xb__logit_gan), xb__logit_gan)\n","    d_loss_gan = xa_gan_loss + xb__gan_loss\n","    gp = models.gradient_penalty(D, xa)\n","\n","xa_loss_att = tf.losses.sigmoid_cross_entropy(a, xa_logit_att)\n","\n","d_loss = d_loss_gan + gp * 10.0 + xa_loss_att\n","\n","# generator losses\n","if mode == 'wgan':\n","    xb__loss_gan = -tf.reduce_mean(xb__logit_gan)\n","elif mode == 'lsgan':\n","    xb__loss_gan = tf.losses.mean_squared_error(tf.ones_like(xb__logit_gan), xb__logit_gan)\n","elif mode == 'dcgan':\n","    xb__loss_gan = tf.losses.sigmoid_cross_entropy(tf.ones_like(xb__logit_gan), xb__logit_gan)\n","\n","xb__loss_att = tf.losses.sigmoid_cross_entropy(b, xb__logit_att)\n","xa__loss_rec = tf.losses.absolute_difference(xa, xa_)\n","\n","g_loss = xb__loss_gan + xb__loss_att * 10.0 + xa__loss_rec * 100.0\n","\n","#global_step\n","global_step = tf.Variable(initial_value=0,\n","                          name='global_step', trainable=False)\n","\n","# optim\n","d_var = trainable_variables('D')\n","d_step = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(d_loss, var_list=d_var)\n","\n","g_var = trainable_variables('G')\n","g_step = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(g_loss, var_list=g_var,global_step=global_step)\n","\n","# summary\n","d_summary = summary({\n","    d_loss_gan: 'd_loss_gan',\n","    gp: 'gp',\n","    xa_loss_att: 'xa_loss_att',\n","}, scope='D')\n","\n","g_summary = summary({\n","    xb__loss_gan: 'xb__loss_gan',\n","    xb__loss_att: 'xb__loss_att',\n","    xa__loss_rec: 'xa__loss_rec',\n","}, scope='G')\n","\n","lr_summary = summary({lr: 'lr'}, scope='Learning_Rate')\n","\n","d_summary = tf.summary.merge([d_summary, lr_summary])\n","\n","# sample\n","x_sample = Gdec(Genc(xa_sample, is_training=False), _b_sample, is_training=False)\n","\n","\n","# ==============================================================================\n","# =                                    train                                   =\n","# ==============================================================================\n","\n","# iteration counter\n","it_cnt, update_cnt = counter()\n","\n","# saver\n","saver = tf.train.Saver(max_to_keep=1)\n","\n","# summary writer\n","summary_writer = tf.summary.FileWriter('output/summaries', sess.graph)\n","\n","# initialization\n","\n","ckpt_dir = load_ckpt()\n","\n","\n"," # train\n","try:\n","    # data for sampling\n","    xa_sample_ipt, a_sample_ipt = val_data.get_next()\n","    b_sample_ipt_list = [a_sample_ipt]  # the first is for reconstruction\n","    for i in range(len(atts)):\n","        tmp = np.array(a_sample_ipt, copy=True)\n","        tmp[:, i] = 1 - tmp[:, i]   # inverse attribute\n","        tmp = data.Celeba.check_attribute_conflict(tmp, atts[i], atts)\n","        b_sample_ipt_list.append(tmp)\n","\n","    it_per_epoch = len(tr_data) // (batch_size * (n_d + 1))\n","    max_it = epoch * it_per_epoch\n","    for it in range(sess.run(it_cnt), max_it):\n","        with my_time.Timer(is_output=False) as t:\n","            sess.run(update_cnt)\n","\n","            # which epoch\n","            epoch = it//it_per_epoch\n","            it_in_epoch = it%it_per_epoch + 1\n","\n","            # learning rate\n","            lr_ipt = lr_base / (10 ** (epoch // 100))\n","\n","            # train D\n","            with tf.device('/device:XLA_GPU:0'):\n","                \n","                for i in range(n_d):\n","                    d_summary_opt, _ = sess.run([d_summary, d_step], feed_dict={lr: lr_ipt})\n","                summary_writer.add_summary(d_summary_opt, it)\n","            with tf.device('/device:GPU:0'):\n","                # train G\n","                g_summary_opt, _ = sess.run([g_summary, g_step], feed_dict={lr: lr_ipt})\n","                summary_writer.add_summary(g_summary_opt, it)\n","\n","            i_global = sess.run(global_step)\n","\n","            # display\n","            if (it + 1) % 1 == 0:\n","                print(\"Epoch: (%3d) (%5d/%5d) Time: %s! ,global_step :(%d)\" % (epoch, it_in_epoch, it_per_epoch, t,i_global))\n","\n","\n","\n","\n","            # save\n","            if (it + 1) % 700 == 0:\n","                save_path = saver.save(sess, '%s/Epoch_(%d)_(%dof%d).ckpt' % (ckpt_dir, epoch, it_in_epoch, it_per_epoch),global_step=global_step)\n","                print('Model is saved at %s!' % save_path)\n","\n","\n","        # sample\n","            if (it + 1) % 100 == 0:\n","                x_sample_opt_list = [xa_sample_ipt, np.full((n_sample, img_size, img_size // 10, 3), -1.0)]\n","                for i, b_sample_ipt in enumerate(b_sample_ipt_list):\n","                    _b_sample_ipt = (b_sample_ipt * 2 - 1) * thres_int\n","                    if i > 0:   # i == 0 is for reconstruction\n","                        _b_sample_ipt[..., i - 1] = _b_sample_ipt[..., i - 1] * test_int / thres_int\n","                    x_sample_opt_list.append(sess.run(x_sample, feed_dict={xa_sample: xa_sample_ipt, _b_sample: _b_sample_ipt}))\n","                sample = np.concatenate(x_sample_opt_list, 2)\n","\n","                save_dir = 'output/%s/sample_training' % experiment_name\n","                mkdir(save_dir)\n","                imwrite(immerge(sample, n_sample, 1), '%s/Epoch_(%d)_(%dof%d)(g:%d).jpg' % (save_dir, epoch, it_in_epoch, it_per_epoch,i_global))\n","except:\n","    traceback.print_exc()\n","finally:\n","    save_path = saver.save(sess, '%s/Epoch_(%d)_(%dof%d).ckpt' % (ckpt_dir, epoch, it_in_epoch, it_per_epoch),global_step=global_step)\n","    print('Model is saved at %s!' % save_path)\n","    sess.close()"],"execution_count":21,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-0b11918242f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtr_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-eddde6ad323c>\u001b[0m in \u001b[0;36mload_train_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtr_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCeleba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0muse_cropped_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCeleba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0muse_cropped_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtr_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'file_names' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"umBECMDw36KK","colab_type":"text"},"source":["# Testing"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:12:13.819016Z","start_time":"2019-03-23T12:12:13.476186Z"},"id":"7bSjKkf136KL","colab_type":"code","colab":{}},"source":["sess=session()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-03-23T12:13:32.227217Z","start_time":"2019-03-23T12:12:13.824428Z"},"id":"QhFCLYPb36KM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":324},"outputId":"4d3a6249-f804-43dd-938d-f201a6cbd522","executionInfo":{"status":"error","timestamp":1584186987892,"user_tz":-330,"elapsed":992,"user":{"displayName":"sathish jindam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgxqAGaa0hvMFGMa4Ar_3wItgXU-JokaQn9-QGgKw=s64","userId":"12274474612273129219"}}},"source":["\n","init_settings()\n","Genc,Gdec,D = intiliaze_models()\n","\n","te_data = data.Celeba('data', atts, img_size, 1, part='test', sess=sess, crop=not use_cropped_img)\n","\n","xa_sample = tf.placeholder(tf.float32, shape=[None, img_size, img_size, 3])\n","_b_sample = tf.placeholder(tf.float32, shape=[None, n_att])\n","\n","x_sample = Gdec(Genc(xa_sample, is_training=False), _b_sample, is_training=False)\n","\n","load_ckpt()\n"," #sample\n","try:\n","    for idx, batch in enumerate(te_data):\n","        xa_sample_ipt = batch[0]\n","        a_sample_ipt = batch[1]\n","        b_sample_ipt_list = [a_sample_ipt]  # the first is for reconstruction\n","        for i in range(len(atts)):\n","            tmp = np.array(a_sample_ipt, copy=True)\n","            tmp[:, i] = 1 - tmp[:, i]   # inverse attribute\n","            tmp = data.Celeba.check_attribute_conflict(tmp, atts[i], atts)\n","            b_sample_ipt_list.append(tmp)\n","\n","        x_sample_opt_list = [xa_sample_ipt, np.full((1, img_size, img_size // 10, 3), -1.0)]\n","        for i, b_sample_ipt in enumerate(b_sample_ipt_list):\n","            _b_sample_ipt = (b_sample_ipt * 2 - 1) * thres_int\n","            if i > 0:   # i == 0 is for reconstruction\n","                _b_sample_ipt[..., i - 1] = _b_sample_ipt[..., i - 1] * test_int / thres_int\n","            x_sample_opt_list.append(sess.run(x_sample, feed_dict={xa_sample: xa_sample_ipt, _b_sample: _b_sample_ipt}))\n","        sample = np.concatenate(x_sample_opt_list, 2)\n","\n","        save_dir = 'output/sample_testing'\n","            \n","        if not os.path.exists(save_dir):\n","            mkdir(save_dir)\n","        \n","        imwrite(sample.squeeze(0), '%s/%d.png' % (save_dir, idx + 182638))\n","\n","        print('%d.png done!' % (idx + 182638))\n","\n","except:\n","    traceback.print_exc()\n","finally:\n","    sess.close()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Exception ignored in: <bound method Dataset.__del__ of <data.Celeba object at 0x7f887e8acbe0>>\n","Traceback (most recent call last):\n","  File \"/gdrive/My Drive/gan/data.py\", line 81, in __del__\n","    if self._sess:\n","AttributeError: 'Celeba' object has no attribute '_sess'\n"],"name":"stderr"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-f033513b6ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGenc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGdec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintiliaze_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mte_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCeleba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0muse_cropped_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mxa_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'batch_size'"]}]},{"cell_type":"markdown","metadata":{"id":"8m11UQA9W967","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"b_rM34y_5yjI","colab_type":"text"},"source":["# New Section"]}]}